#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Demo Script for Telegram AI Auto Messenger
Ù†Ù…Ø§ÛŒØ´ Ø³Ø±ÛŒØ¹ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒ
"""

import json
import requests
import time

def test_ollama_connection():
    """ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ollama"""
    print("ğŸ¤– ØªØ³Øª Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ollama...")
    
    try:
        response = requests.get("http://127.0.0.1:11500/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            print(f"âœ… Ollama Ù…ØªØµÙ„ Ø§Ø³Øª! ØªØ¹Ø¯Ø§Ø¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§: {len(models)}")
            for model in models:
                print(f"   ğŸ“¦ {model.get('name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
            return True
        else:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„ Ø¨Ù‡ Ollama: {e}")
        print("ğŸ’¡ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø­Ø§ØµÙ„ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ollama Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª:")
        print("   ollama serve")
        return False

def generate_sample_message():
    """ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ AI"""
    print("\nğŸ¯ ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ù†Ù…ÙˆÙ†Ù‡...")
    
    prompt = """Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ù‡Ø³ØªÛŒØ¯. ÛŒÚ© Ù¾ÛŒØ§Ù… Ú©ÙˆØªØ§Ù‡ Ùˆ ØµÙ…ÛŒÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ú¯Ø±ÙˆÙ‡ Ø¯ÙˆØ³ØªØ§Ù† Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.
Ù¾ÛŒØ§Ù… Ø¨Ø§ÛŒØ¯:
- ÙØ§Ø±Ø³ÛŒ Ø¨Ø§Ø´Ø¯
- Ø­Ø¯Ø§Ú©Ø«Ø± 50 Ú©Ù„Ù…Ù‡
- Ø´Ø§Ù…Ù„ ÛŒÚ© Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù…Ù†Ø§Ø³Ø¨
- Ù…Ø«Ø¨Øª Ùˆ Ø§Ù†Ø±Ú˜ÛŒâ€ŒØ¨Ø®Ø´ Ø¨Ø§Ø´Ø¯"""

    try:
        response = requests.post(
            "http://127.0.0.1:11500/api/generate",
            json={
                "model": "llama3.1:8b",
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "top_k": 40
                }
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            message = result.get('response', '').strip()
            print(f"âœ¨ Ù¾ÛŒØ§Ù… ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡:")
            print(f"   {message}")
            return message
        else:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù…: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù…: {e}")
        return None

def show_config_info():
    """Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù†ÙÛŒÚ¯"""
    print("\nğŸ“‹ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù†ÙÛŒÚ¯:")
    
    try:
        with open("ai_config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
            
        print(f"   ğŸ¯ Ú¯Ø±ÙˆÙ‡ Ù‡Ø¯Ù: {config.get('group_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        print(f"   ğŸ†” Chat ID: {config.get('chat_id', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        print(f"   â±ï¸ ÙØ§ØµÙ„Ù‡ Ø²Ù…Ø§Ù†ÛŒ: {config.get('interval_seconds', 30)} Ø«Ø§Ù†ÛŒÙ‡")
        print(f"   ğŸ¤– Ù…Ø¯Ù„ AI: {config.get('ollama_model', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        print(f"   ğŸ­ Ø´Ø®ØµÛŒØª: {config.get('personality', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        print(f"   ğŸ“± ØªÙ„Ú¯Ø±Ø§Ù…: {config.get('telegram_path', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
        
    except FileNotFoundError:
        print("   âš ï¸ ÙØ§ÛŒÙ„ Ú©Ø§Ù†ÙÛŒÚ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯")
    except Exception as e:
        print(f"   âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú©Ø§Ù†ÙÛŒÚ¯: {e}")

def main():
    """Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ"""
    print("ğŸš€ Telegram AI Auto Messenger - Demo")
    print("=" * 50)
    
    # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ù†ÙÛŒÚ¯
    show_config_info()
    
    # ØªØ³Øª Ø§ØªØµØ§Ù„ Ollama
    if test_ollama_connection():
        # ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ù†Ù…ÙˆÙ†Ù‡
        generate_sample_message()
    
    print("\n" + "=" * 50)
    print("âœ… Demo ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")
    print("ğŸ’¡ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ:")
    print("   python telegram_ai_messenger.py")

if __name__ == "__main__":
    main()
