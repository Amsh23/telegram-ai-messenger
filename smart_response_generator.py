#!/usr/bin/env python3
"""
ğŸ§  Smart Response Generator - ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯
Ù…Ø§Ú˜ÙˆÙ„ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ù…ØªÙ†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ú†Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
"""

import json
import time
import requests
import random
import logging
from datetime import datetime

class SmartResponseGenerator:
    """ØªÙˆÙ„ÛŒØ¯Ú©Ù†Ù†Ø¯Ù‡ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    
    def __init__(self, config):
        self.config = config
        self.response_history = {}
        self.user_profiles = {}
        
        # Ù„Ø§Ú¯
        self.logger = logging.getLogger("SmartResponseGenerator")
        
        # Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø®
        self.response_templates = self._load_response_templates()
    
    def generate_response(self, message_data, chat_info):
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        try:
            message_content = message_data.get('content', '')
            message_type = message_data.get('type', 'normal')
            sender = message_data.get('sender', 'Ú©Ø§Ø±Ø¨Ø±')
            
            self.logger.info(f"ğŸ§  ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø±Ø§ÛŒ: {message_content[:50]}...")
            
            # ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù¾Ø§Ø³Ø® Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
            response_type = self._determine_response_type(message_data, chat_info)
            
            # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ AI
            ai_response = self._generate_ai_response(message_data, chat_info, response_type)
            
            if ai_response:
                # Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø³Ø®
                personalized_response = self._personalize_response(ai_response, chat_info, sender)
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
                self._save_to_history(chat_info.get('name', ''), message_content, personalized_response)
                
                return personalized_response
            else:
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø§Ø³Ø® fallback
                return self._get_fallback_response(message_type, sender)
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {e}")
            return self._get_emergency_response()
    
    def _determine_response_type(self, message_data, chat_info):
        """ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ù¾Ø§Ø³Ø®"""
        message_type = message_data.get('type', 'normal')
        priority = message_data.get('priority', 'medium')
        
        if message_type == 'question':
            return 'informative'
        elif message_type == 'request':
            return 'helpful'
        elif message_type == 'complaint':
            return 'supportive'
        elif message_type == 'thanks':
            return 'appreciative'
        else:
            return 'friendly'
    
    def _generate_ai_response(self, message_data, chat_info, response_type):
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
        try:
            # Ø³Ø§Ø®Øª prompt Ù¾ÛŒØ´Ø±ÙØªÙ‡
            prompt = self._build_advanced_prompt(message_data, chat_info, response_type)
            
            settings = self._get_ollama_settings()
            
            response = requests.post(
                f"{settings['url']}/api/generate",
                json={
                    "model": settings['text_model'],
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": 200
                    }
                },
                timeout=settings['text_timeout']
            )
            
            if response.status_code == 200:
                result = response.json().get('response', '').strip()
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ Ù¾Ø§Ø³Ø®
                improved_response = self._improve_response(result)
                
                return improved_response
            
            return None
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ AI: {e}")
            return None
    
    def _build_advanced_prompt(self, message_data, chat_info, response_type):
        """Ø³Ø§Ø®Øª prompt Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù¾Ø§ÛŒÙ‡
        message_content = message_data.get('content', '')
        sender = message_data.get('sender', 'Ú©Ø§Ø±Ø¨Ø±')
        chat_name = chat_info.get('name', 'Ú†Øª')
        chat_type = chat_info.get('type', 'private')
        
        # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª
        history_context = self._get_chat_history_context(chat_name)
        
        # Ø²Ù…Ø§Ù† ÙØ¹Ù„ÛŒ
        current_time = datetime.now().strftime("%H:%M")
        
        prompt = f"""ØªÙˆ ÛŒÚ© Ø§Ø¯Ù…ÛŒÙ† Ø¨Ø§Ù‡ÙˆØ´ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¯Ø± {chat_name} ÙØ¹Ø§Ù„ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Øª:
- Ù†ÙˆØ¹ Ú†Øª: {chat_type}
- ÙØ±Ø³ØªÙ†Ø¯Ù‡: {sender}
- Ø²Ù…Ø§Ù†: {current_time}
- Ù†ÙˆØ¹ Ù¾Ø§Ø³Ø® Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: {response_type}

Ù¾ÛŒØ§Ù… Ø¯Ø±ÛŒØ§ÙØªÛŒ:
"{message_content}"

{history_context}

Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ:
- Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯ (Ø­Ø¯Ø§Ú©Ø«Ø± 2 Ø®Ø·)
- Ù„Ø­Ù† Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
- Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
- Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡
- Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ ÙÙ†ÛŒ Ø§Ø³ØªØŒ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ø¹Ù…Ù„ÛŒ Ø¨Ø¯Ù‡
- Ø§Ú¯Ø± ØªØ´Ú©Ø± Ø§Ø³ØªØŒ Ø®ÙˆØ´Ø­Ø§Ù„ÛŒ Ù†Ø´Ø§Ù† Ø¨Ø¯Ù‡
- Ø§Ú¯Ø± Ø´Ú©Ø§ÛŒØª Ø§Ø³ØªØŒ Ù‡Ù…Ø¯Ø±Ø¯ÛŒ Ùˆ Ø­Ù…Ø§ÛŒØª Ú©Ù†

ÙÙ‚Ø· Ù…ØªÙ† Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ØŒ Ù‡ÛŒÚ† ØªÙˆØ¶ÛŒØ­ Ø§Ø¶Ø§ÙÛŒ Ù†Ø¯Ø§Ø¯Ù‡."""

        return prompt
    
    def _get_chat_history_context(self, chat_name):
        """Ú¯Ø±ÙØªÙ† Ø²Ù…ÛŒÙ†Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª"""
        if chat_name in self.response_history:
            recent_messages = self.response_history[chat_name][-3:]  # Ø¢Ø®Ø±ÛŒÙ† 3 Ù¾ÛŒØ§Ù…
            if recent_messages:
                context = "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø®ÛŒØ±:\n"
                for msg in recent_messages:
                    context += f"- {msg['message'][:50]}... â†’ {msg['response'][:50]}...\n"
                return context
        return ""
    
    def _improve_response(self, response):
        """Ø¨Ù‡Ø¨ÙˆØ¯ Ùˆ Ù¾Ø§Ù„Ø§ÛŒØ´ Ù¾Ø§Ø³Ø®"""
        # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        response = response.strip()
        
        # Ø­Ø°Ù Ù†Ù‚Ù„ Ù‚ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
        if response.startswith('"') and response.endswith('"'):
            response = response[1:-1]
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø§Ú¯Ø± Ù†Ø¯Ø§Ø´Øª
        if not any(char in response for char in ['ğŸ˜Š', 'ğŸ˜„', 'ğŸ‘', 'ğŸ™', 'â¤ï¸', 'ğŸŒŸ', 'âœ¨']):
            response = self._add_appropriate_emoji(response)
        
        return response
    
    def _add_appropriate_emoji(self, response):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ù…Ù†Ø§Ø³Ø¨"""
        # Ø§ÛŒÙ…ÙˆØ¬ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø­ØªÙˆØ§ÛŒ Ù¾Ø§Ø³Ø®
        if any(word in response for word in ['Ù…Ù…Ù†ÙˆÙ†', 'Ù…ØªØ´Ú©Ø±', 'Ø³Ù¾Ø§Ø³']):
            return response + " ğŸ™"
        elif any(word in response for word in ['Ø®ÙˆØ´Ø­Ø§Ù„', 'Ø®ÙˆØ¨', 'Ø¹Ø§Ù„ÛŒ']):
            return response + " ğŸ˜Š"
        elif any(word in response for word in ['Ú©Ù…Ú©', 'Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ']):
            return response + " ğŸ¤"
        elif any(word in response for word in ['Ù…ÙˆÙÙ‚', 'Ø¨Ù‡ØªØ±']):
            return response + " âœ¨"
        else:
            return response + " ğŸ˜Š"
    
    def _personalize_response(self, response, chat_info, sender):
        """Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ù¾Ø§Ø³Ø®"""
        try:
            chat_type = chat_info.get('type', 'private')
            
            # Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Ú†Øª
            if chat_type == 'group':
                # Ø¯Ø± Ú¯Ø±ÙˆÙ‡â€ŒÙ‡Ø§ Ø§Ø³Ù… ÙØ±Ø¯ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                if sender and sender != 'Ú©Ø§Ø±Ø¨Ø±':
                    response = f"{sender.split()[0]} Ø¹Ø²ÛŒØ²ØŒ {response}"
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙ†ÙˆØ¹
            response = self._add_variation(response)
            
            return response
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ: {e}")
            return response
    
    def _add_variation(self, response):
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÙ†ÙˆØ¹ Ø¨Ù‡ Ù¾Ø§Ø³Ø®"""
        # ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ØªØ±Ø§Ø¯Ù
        variations = {
            'Ø³Ù„Ø§Ù…': ['Ø³Ù„Ø§Ù…', 'Ø¯Ø±ÙˆØ¯', 'Ø§Ø­ÙˆØ§Ù„'],
            'Ù…Ù…Ù†ÙˆÙ†': ['Ù…Ù…Ù†ÙˆÙ†', 'Ù…ØªØ´Ú©Ø±Ù…', 'Ø³Ù¾Ø§Ø³'],
            'Ø®ÙˆØ´Ø­Ø§Ù„Ù…': ['Ø®ÙˆØ´Ø­Ø§Ù„Ù…', 'Ø®ÙˆØ´ÙˆÙ‚ØªÙ…', 'Ù…Ø³Ø±ÙˆØ±Ù…'],
            'Ú©Ù…Ú©': ['Ú©Ù…Ú©', 'Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ', 'ÛŒØ§Ø±ÛŒ']
        }
        
        for original, alternatives in variations.items():
            if original in response:
                replacement = random.choice(alternatives)
                response = response.replace(original, replacement, 1)
                break
        
        return response
    
    def _get_fallback_response(self, message_type, sender):
        """Ù¾Ø§Ø³Ø® fallback"""
        responses = self.response_templates.get(message_type, self.response_templates['normal'])
        selected_response = random.choice(responses)
        
        # Ø´Ø®ØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø³Ø§Ø¯Ù‡
        if '{sender}' in selected_response and sender:
            selected_response = selected_response.replace('{sender}', sender.split()[0])
        
        return selected_response
    
    def _get_emergency_response(self):
        """Ù¾Ø§Ø³Ø® Ø§Ø¶Ø·Ø±Ø§Ø±ÛŒ"""
        emergency_responses = [
            "Ø³Ù„Ø§Ù…! ğŸ‘‹ Ø¯Ø± Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ù‡Ø³ØªÙ…",
            "Ù…Ù…Ù†ÙˆÙ† Ú©Ù‡ Ø¨Ø§ Ù…Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ù‡Ø³ØªÛŒØ¯ ğŸ™",
            "Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©ØªØ§Ù† Ú©Ù†Ù…ØŸ ğŸ˜Š"
        ]
        return random.choice(emergency_responses)
    
    def _save_to_history(self, chat_name, message, response):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡"""
        try:
            if chat_name not in self.response_history:
                self.response_history[chat_name] = []
            
            self.response_history[chat_name].append({
                'timestamp': datetime.now().isoformat(),
                'message': message,
                'response': response
            })
            
            # Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒ ÙÙ‚Ø· 50 Ù¾ÛŒØ§Ù… Ø¢Ø®Ø±
            if len(self.response_history[chat_name]) > 50:
                self.response_history[chat_name] = self.response_history[chat_name][-50:]
                
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")
    
    def _load_response_templates(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù‚Ø§Ù„Ø¨â€ŒÙ‡Ø§ÛŒ Ù¾Ø§Ø³Ø®"""
        return {
            'question': [
                "Ø§ÛŒÙ† Ø³ÙˆØ§Ù„ Ø¬Ø§Ù„Ø¨ÛŒ Ø§Ø³Øª! ğŸ¤” Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯ Ú©Ù…Ú©ØªØ§Ù† Ú©Ù†Ù…",
                "Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ Ø³ÙˆØ§Ù„ Ú©Ø±Ø¯ÛŒØ¯ ğŸ˜Š Ù¾Ø§Ø³Ø® Ø´Ù…Ø§:",
                "Ø³ÙˆØ§Ù„ Ø®ÙˆØ¨ÛŒ Ù¾Ø±Ø³ÛŒØ¯ÛŒØ¯! ğŸ‘ Ø§ÛŒÙ†Ø·ÙˆØ± ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…:",
            ],
            'request': [
                "Ø­ØªÙ…Ø§Ù‹! ğŸ˜Š Ú©Ù…Ú©ØªØ§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ù…",
                "Ø§Ù„Ø¨ØªÙ‡ Ú©Ù‡ Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú© Ú©Ù†Ù… ğŸ¤",
                "Ø¨Ø§ Ú©Ù…Ø§Ù„ Ù…ÛŒÙ„! âœ¨ Ø§ÛŒÙ† Ú©Ø§Ø± Ø±Ùˆ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ¯Ù…",
            ],
            'complaint': [
                "Ù…ØªØ£Ø³ÙÙ… Ú©Ù‡ Ø§ÛŒÙ† Ù…Ø´Ú©Ù„ Ù¾ÛŒØ´ Ø§ÙˆÙ…Ø¯Ù‡ ğŸ˜” Ú©Ù…Ú©ØªØ§Ù† Ù…ÛŒâ€ŒÚ©Ù†Ù…",
                "Ø¯Ø±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù… Ùˆ Ù‡Ù…Ø¯Ø±Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… ğŸ™ Ø¨ÛŒØ§ÛŒØ¯ Ø­Ù„Ø´ Ú©Ù†ÛŒÙ…",
                "Ø¨Ø¨Ø®Ø´ÛŒØ¯ Ú©Ù‡ Ù†Ø§Ø±Ø§Ø­Øª Ø´Ø¯ÛŒØ¯ ğŸ˜ Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù… Ø­Ù„ Ú©Ù†Ù…",
            ],
            'thanks': [
                "Ù‚Ø§Ø¨Ù„ Ù†Ø¯Ø§Ø´Øª! ğŸ˜Š Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ø®Ø¯Ù…ØªÙ…",
                "Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ ØªÙˆÙ†Ø³ØªÙ… Ú©Ù…Ú© Ú©Ù†Ù… ğŸŒŸ",
                "Ù‡Ø± ÙˆÙ‚Øª Ù†ÛŒØ§Ø² Ø¯Ø§Ø´ØªÛŒØ¯ Ø¯Ø± Ø®Ø¯Ù…ØªÙ… ğŸ™",
            ],
            'normal': [
                "Ø³Ù„Ø§Ù…! ğŸ‘‹ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©ØªØ§Ù† Ú©Ù†Ù…ØŸ",
                "Ø¯Ø± Ø®Ø¯Ù…Øª Ø´Ù…Ø§ Ù‡Ø³ØªÙ… ğŸ˜Š",
                "Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ Ø¨Ø§ Ù…Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ù‡Ø³ØªÛŒØ¯ ğŸŒŸ",
            ]
        }
    
    def _get_ollama_settings(self):
        """ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ollama"""
        return {
            'url': self.config.get('ollama_url', 'http://127.0.0.1:11434'),
            'text_model': self.config.get('text_model', 'llama3.1:8b'),
            'text_timeout': self.config.get('text_timeout', 60)
        }
    
    def get_response_statistics(self):
        """Ø¢Ù…Ø§Ø± Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ"""
        total_chats = len(self.response_history)
        total_responses = sum(len(messages) for messages in self.response_history.values())
        
        return {
            'total_chats': total_chats,
            'total_responses': total_responses,
            'avg_responses_per_chat': total_responses / max(total_chats, 1)
        }
