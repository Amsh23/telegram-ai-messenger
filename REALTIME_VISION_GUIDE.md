# 🎯 راهنمای Vision AI بلادرنگ

## ویژگی‌های جدید سیستم Vision AI

### 🚀 قابلیت‌های اصلی
- **هر ثانیه اسکرین‌شات**: گرفتن تصویر مداوم از صفحه تلگرام
- **تحلیل Computer Vision**: تشخیص پیام‌ها و چت‌ها با Ollama llava
- **پاسخ‌دهی خودکار**: تولید و ارسال پاسخ مناسب به‌صورت فوری
- **کنترل فوکوس**: حفظ تمرکز روی پنجره تلگرام
- **آمارگیری بلادرنگ**: نمایش عملکرد و موفقیت‌ها

### 📋 پیش‌نیازها

#### 1. Ollama Vision Model
```bash
# نصب Ollama
# دانلود از: https://ollama.ai

# نصب مدل llava برای Vision
ollama pull llava
```

#### 2. کتابخانه‌های Python
```bash
pip install -r requirements.txt
```

#### 3. تنظیمات سیستم
- **رزولوشن**: 1920x1080 یا بالاتر (بهتر)
- **رم**: حداقل 8GB (16GB توصیه می‌شود)
- **فضای خالی**: 5GB برای مدل Vision

### ⚙️ تنظیمات ai_config.json

```json
{
  "ollama_url": "http://127.0.0.1:11434",
  "ollama_model": "llama3.1:8b",
  "ollama_vision_model": "llava",
  "vision_enabled": true,
  "realtime_vision": true,
  "vision_interval": 1.0
}
```

### 🎮 نحوه استفاده

#### 1. راه‌اندازی
1. اطمینان از اجرای Ollama در پس‌زمینه
2. باز کردن برنامه telegram_ai_messenger.py
3. کلیک روی دکمه **🎯 حالت همه‌کاره (AI Vision)**

#### 2. فرآیند خودکار
```
هر 1 ثانیه:
اسکرین‌شات گرفتن
    ↓
تحلیل Vision AI
    ↓
تشخیص پیام‌های جدید
    ↓
تولید پاسخ مناسب
    ↓
ارسال خودکار
```

### 📊 نظارت عملکرد

برنامه به‌صورت بلادرنگ نمایش می‌دهد:
- **تعداد اسکرین‌شات‌ها**: 📸
- **تحلیل‌های Vision**: 👁️
- **پاسخ‌های ارسالی**: 💬
- **نرخ موفقیت**: 📈

### 🔧 تنظیمات پیشرفته

#### سرعت Vision
```python
vision_interval = 1.0    # هر 1 ثانیه (سریع)
vision_interval = 2.0    # هر 2 ثانیه (متعادل)
vision_interval = 5.0    # هر 5 ثانیه (آرام)
```

#### حداکثر چرخه‌ها
```python
max_vision_cycles = 200  # 200 چرخه (پیش‌فرض)
max_vision_cycles = 500  # 500 چرخه (بیشتر)
```

### 🎯 بهینه‌سازی عملکرد

#### برای بهترین نتایج:
1. **پنجره تلگرام را بزرگ کنید** (تمام صفحه)
2. **چت مورد نظر را باز کنید**
3. **برنامه‌های اضافی را ببندید** (کاهش مصرف رم)
4. **اتصال اینترنت پایدار** داشته باشید

#### تنظیمات Ollama:
```bash
# افزایش حافظه مدل
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_MAX_LOADED_MODELS=2
```

### 🚨 عیب‌یابی

#### مشکلات رایج:

**1. Vision کار نمی‌کند**
```
بررسی کنید:
- Ollama اجرا شده؟ (http://localhost:11434)
- مدل llava نصب شده؟ (ollama list)
- پورت 11434 باز است؟
```

**2. اسکرین‌شات خالی**
```
حل:
- اجازه‌های Screen Capture
- غیرفعال کردن antivirus
- اجرا به عنوان Administrator
```

**3. پاسخ‌ها نامناسب**
```
بهبود:
- کیفیت تصویر بالاتر
- نور مناسب صفحه
- فونت واضح‌تر
```

### 📈 نکات بهبود

1. **برای گروه‌های شلوغ**: افزایش interval به 2-3 ثانیه
2. **برای چت‌های خصوصی**: کاهش interval به 0.5 ثانیه
3. **برای بررسی دقیق**: افزایش timeout Vision
4. **برای سرعت بیشتر**: کاهش resolution

### 🎮 کلیدهای میانبر

- **شروع/توقف**: کلیک دکمه Vision
- **نظارت آمار**: مشاهده پنل وضعیت
- **تنظیمات**: ویرایش ai_config.json

### 💡 نکات حرفه‌ای

#### الگوهای پیشرفته:
```python
# تشخیص نوع چت
if "گروه" in chat_type:
    response_style = "formal"
else:
    response_style = "friendly"

# تطبیق با زمان
current_hour = datetime.now().hour
if 6 <= current_hour <= 12:
    greeting = "صبح بخیر"
elif 12 <= current_hour <= 18:
    greeting = "ظهر بخیر"
else:
    greeting = "عصر بخیر"
```

#### بهینه‌سازی مصرف:
```python
# تنظیم Quality برای سرعت
screenshot_quality = 70  # کیفیت متوسط
compress_images = True   # فشرده‌سازی
```

### 🔮 آینده پروژه

**ویژگی‌های در حال توسعه**:
- تشخیص emotion در پیام‌ها
- پاسخ‌دهی چندزبانه
- یکپارچه‌سازی با GPT-4 Vision
- ذخیره‌سازی تاریخچه Vision
- تحلیل sentiment realtime

---

## 🎯 نتیجه‌گیری

سیستم Vision AI بلادرنگ شما را قادر می‌سازد تا:
- **بدون دخالت دستی** با چت‌ها تعامل کنید
- **با دقت بالا** پیام‌ها را تحلیل کنید  
- **پاسخ‌های مناسب** تولید کنید
- **عملکرد بلادرنگ** داشته باشید

**موفق باشید!** 🚀
